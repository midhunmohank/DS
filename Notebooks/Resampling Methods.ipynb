{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods for Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is resampling?\n",
    "A resampling method is a tool consisting in repeatedly drawing samples from a dataset and calculating statistics and metrics on each of those samples in order to obtain further information about something, in the machine learning setting, this something is the performance of a model. But in case of merely statistical analysis this could be additional insight about the behavior of some parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use resampling for two goals:\n",
    "\n",
    "To select among model configurations\n",
    "To evaluate the performance of our models in new data\n",
    "There are two kinds of problems that can emerge from selecting a sub-optimal resampling approach\n",
    "\n",
    "We can get a biased estimate of model performance (i.e., we can systematically under or over-estimate its performance)\n",
    "We can get an imprecise estimate of model performance (i.e., high variance in our model performance metric)\n",
    "Essentially, this is the bias and variance problem again, but now not with respect to the model’s actual performance but instead with our estimate of how the model will perform\n",
    "\n",
    "This is a very important distinction to keep in mind or you will be confused as we discuss bias and variance into the future. We have:\n",
    "\n",
    "bias and variance of model performance (i.e., the predictions the model makes)\n",
    "bias and variance of our estimate of how well the model will perform in new data\n",
    "different factors affect each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, LeaveOneOut, RepeatedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "#Import graphical plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is hosted on my github repository\n",
    "url = \"https://raw.githubusercontent.com/midhunmohank/DS/master/Datasets/heart_cleveland_upload.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Feature Infromation\n",
    "1. age: age in years\n",
    "2. sex: sex (1 = male; 0 = female)\n",
    "3. cp: chest pain type\n",
    "        -- Value 0: typical angina\n",
    "        -- Value 1: atypical angina\n",
    "        -- Value 2: non-anginal pain\n",
    "        -- Value 3: asymptomatic\n",
    "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol: serum cholestoral in mg/dl\n",
    "6. fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "7. restecg: resting electrocardiographic results\n",
    "        -- Value 0: normal\n",
    "        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. thalach: maximum heart rate achieved\n",
    "9. exang: exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak = ST depression induced by exercise relative to rest\n",
    "11. slope: the slope of the peak exercise ST segment\n",
    "        -- Value 0: upsloping\n",
    "        -- Value 1: flat\n",
    "        -- Value 2: downsloping\n",
    "12. ca: number of major vessels (0-3) colored by flourosopy\n",
    "13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect \n",
    "and the label\n",
    "14. condition: 0 = no disease, 1 = disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 297 entries, 0 to 296\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        297 non-null    int64  \n",
      " 1   sex        297 non-null    int64  \n",
      " 2   cp         297 non-null    int64  \n",
      " 3   trestbps   297 non-null    int64  \n",
      " 4   chol       297 non-null    int64  \n",
      " 5   fbs        297 non-null    int64  \n",
      " 6   restecg    297 non-null    int64  \n",
      " 7   thalach    297 non-null    int64  \n",
      " 8   exang      297 non-null    int64  \n",
      " 9   oldpeak    297 non-null    float64\n",
      " 10  slope      297 non-null    int64  \n",
      " 11  ca         297 non-null    int64  \n",
      " 12  thal       297 non-null    int64  \n",
      " 13  condition  297 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 32.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.542088</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>2.158249</td>\n",
       "      <td>131.693603</td>\n",
       "      <td>247.350168</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>149.599327</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.602694</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.461279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.049736</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.964859</td>\n",
       "      <td>17.762806</td>\n",
       "      <td>51.997583</td>\n",
       "      <td>0.352474</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>22.941562</td>\n",
       "      <td>0.469761</td>\n",
       "      <td>1.166123</td>\n",
       "      <td>0.618187</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.956690</td>\n",
       "      <td>0.499340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean    54.542088    0.676768    2.158249  131.693603  247.350168    0.144781   \n",
       "std      9.049736    0.468500    0.964859   17.762806   51.997583    0.352474   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    2.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    2.000000  130.000000  243.000000    0.000000   \n",
       "75%     61.000000    1.000000    3.000000  140.000000  276.000000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.996633  149.599327    0.326599    1.055556    0.602694    0.676768   \n",
       "std      0.994914   22.941562    0.469761    1.166123    0.618187    0.938965   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    1.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    3.000000   \n",
       "\n",
       "             thal   condition  \n",
       "count  297.000000  297.000000  \n",
       "mean     0.835017    0.461279  \n",
       "std      0.956690    0.499340  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    0.000000  \n",
       "75%      2.000000    1.000000  \n",
       "max      2.000000    1.000000  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   69    1   0       160   234    1        2      131      0      0.1      1   \n",
       "1   69    0   0       140   239    0        0      151      0      1.8      0   \n",
       "2   66    0   0       150   226    0        0      114      0      2.6      2   \n",
       "3   65    1   0       138   282    1        2      174      0      1.4      1   \n",
       "4   64    1   0       110   211    0        2      144      1      1.8      1   \n",
       "\n",
       "   ca  thal  condition  \n",
       "0   1     0          0  \n",
       "1   2     0          0  \n",
       "2   0     0          0  \n",
       "3   1     0          1  \n",
       "4   0     0          0  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "sex          0\n",
       "cp           0\n",
       "trestbps     0\n",
       "chol         0\n",
       "fbs          0\n",
       "restecg      0\n",
       "thalach      0\n",
       "exang        0\n",
       "oldpeak      0\n",
       "slope        0\n",
       "ca           0\n",
       "thal         0\n",
       "condition    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 14)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6n/jn9tfjdx2f98kc2l68s832bm0000gn/T/ipykernel_15554/948175804.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  features = df.drop('condition', 1)\n"
     ]
    }
   ],
   "source": [
    "target = df['condition']\n",
    "features = df.drop('condition', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this artcile, we will focus on assessing the performance of a single model configuration\n",
    "\n",
    "1. Logistic regression algorithm\n",
    "2. No hyper-parameters\n",
    "3. All available predictors and we will call the held-out set a test set and use it to evaluate the expected future performance of this single configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/midhunmohan/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score = model.score(features, target)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave One Out Cross Validation\n",
    "\n",
    "Let’s turn to a new resampling technique and start with some questions to motivate it\n",
    "\n",
    "How could you use this single validation set approach to get the least biased estimate of model performance with your n = 303 dataset that would still allow you to estimate its performance in a held out test set?\n",
    "\n",
    "What will be the biggest problem with this approach?\n",
    "\n",
    "How might you reduce this problem?\n",
    "\n",
    "Comparisons across LOOCV and Single Validation Set Approaches\n",
    "\n",
    "The performance estimate from LOOCV has less bias than the single validation set method (because the models that are evaluated were fit with close to the full n of the final model)\n",
    "\n",
    "LOOCV uses all observations as “test” at some point. Less variance than single 20% or 50% validation set?\n",
    "\n",
    "But…\n",
    "\n",
    "LOOCV can be computationally expensive (need to fit and evaluate the same model configuration n times). This is a real problem when you are also working with a high number of model configurations (i.e., number fits = n * number of model configurations).\n",
    "LOOCV eventually uses all the data for test across the ‘n’ test sets. Averaging also helps reduce variance in the performance metric.\n",
    "\n",
    "However, averaging reduces variance to a greater degree when the performance measures being averaged are less related/more independent.\n",
    "\n",
    "The n fitted models are VERY similar in LOOCV b/c they are each fit on almost the same data (each with n-1 observations)\n",
    "\n",
    "K-fold cross validation (next method) improves the variance of the average performance metric by averaging across more independent (less overlapping) training sets\n",
    "\n",
    "For this reason, it is superior and (always?) preferred over LOOCV\n",
    "\n",
    "We are not demonstrating LOOCV b/c we strongly prefer other methods (K-fold)\n",
    "\n",
    "Still important to understand it conceptually and its strengths/weaknesses\n",
    "If you wanted to use this resampling approach, simply substitute loo_cv() for vfold_cv() in the next example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation\n",
    "\n",
    "1. Divide the observations into K equal size independent “folds” (each observation appears in only one fold)\n",
    "2. Hold out 1 of these folds (1/Kth of the dataset) to use as a test set\n",
    "3. Fit a model in the remaining K-1 folds\n",
    "4. Repeat until each of the folds has been held out once\n",
    "5. Performance estimate is the average performance across the K held out folds\n",
    "6. Common values of K are 5 and 10\n",
    "\n",
    "Note that K is sometimes referred to as V in some fields/literatures (Don’t blame me!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "model = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(model, X_train, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.381% (9.216%)\n"
     ]
    }
   ],
   "source": [
    "# Output the accuracy. Calculate the mean and std across all folds. \n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can repeat the K-fold procedure multiple times with new splits for a different mix of K folds each time\n",
    "\n",
    "Two benefits:\n",
    "\n",
    "1. More stable performance estimate (because averaged over more folds: repeats * K)\n",
    "2. Many more estimates of performance to characterize (SE; plot) of your performance estimate\n",
    "3. But it is computationally expensive (depending on number of repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repeatedkfold = RepeatedKFold(n_splits=10, n_repeats = 10,random_state=0)\n",
    "model = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93333333, 0.66666667, 0.8       , 0.93333333, 0.93333333,\n",
       "       0.86666667, 0.73333333, 0.8       , 0.85714286, 0.71428571,\n",
       "       0.93333333, 1.        , 0.8       , 1.        , 0.86666667,\n",
       "       0.73333333, 0.86666667, 0.8       , 0.71428571, 0.71428571,\n",
       "       0.93333333, 0.8       , 0.8       , 0.8       , 0.93333333,\n",
       "       0.8       , 0.8       , 0.66666667, 0.92857143, 0.78571429,\n",
       "       0.86666667, 1.        , 0.8       , 0.73333333, 0.86666667,\n",
       "       0.86666667, 0.8       , 0.86666667, 0.85714286, 0.78571429,\n",
       "       0.93333333, 1.        , 0.6       , 0.86666667, 0.86666667,\n",
       "       0.86666667, 0.66666667, 0.86666667, 1.        , 0.78571429,\n",
       "       0.86666667, 0.86666667, 0.66666667, 0.86666667, 0.93333333,\n",
       "       0.93333333, 0.73333333, 0.93333333, 0.92857143, 0.85714286,\n",
       "       0.86666667, 0.73333333, 0.93333333, 0.8       , 0.8       ,\n",
       "       0.86666667, 0.86666667, 0.86666667, 0.78571429, 1.        ,\n",
       "       0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.86666667,\n",
       "       0.73333333, 0.86666667, 0.93333333, 0.57142857, 0.85714286,\n",
       "       0.86666667, 0.93333333, 0.93333333, 0.86666667, 0.66666667,\n",
       "       0.66666667, 1.        , 0.86666667, 0.64285714, 0.78571429,\n",
       "       1.        , 0.86666667, 0.86666667, 0.73333333, 0.86666667,\n",
       "       0.73333333, 0.86666667, 0.8       , 0.85714286, 0.78571429])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeatedresults = cross_val_score(model, X_train, y_train, cv=Repeatedkfold)\n",
    "repeatedresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.381% (9.216%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisons between repeated K-fold and K-fold\n",
    "\n",
    "Repeated K-fold:\n",
    "\n",
    "1. Has same bias as K-fold (still fitting models with K-1 folds)\n",
    "2. Has all the benefits of single K-fold\n",
    "3. Has even more stable estimate of performance (mean over more folds/repeats)\n",
    "4. Provides more info about distribution for the performance estimate\n",
    "5. But is more computationally expensive\n",
    "6. Repeated K-fold is preferred over K-fold to the degree possible based on computational limitations (parallel, N, p, statistical algorithm, # of model configurations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thumb Rules Associated with K Fold\n",
    "Now, we will discuss a few thumb rules while playing with K – fold\n",
    "\n",
    "1. K should be always >= 2 and = to number of records, (LOOCV)\n",
    "2. If 2 then just 2 iterations\n",
    "3. If K=No of records in the dataset, then 1 for testing and n- for training\n",
    "4. The optimized value for the K is 10 and used with the data of good size. (Commonly used)\n",
    "5. If the K value is too large, then this will lead to less variance across the training set and limit the model currency difference across the iterations.\n",
    "6. The number of folds is indirectly proportional to the size of the data set, which means, if the dataset size is too small, the number of folds can increase.\n",
    "7. Larger values of K eventually increase the running time of the cross-validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bootstrap sample is a random sample taken with replacement (i.e., same observations can be sampled multiple times within one bootstrap sample)\n",
    "\n",
    "If you bootstrap a new sample of size n from a dataset with sample size n, approximately 63.2% of the original observations end up in the bootstrap sample\n",
    "\n",
    "The remaining 36.8% of the observations are often called the “out of bag” (OOB) samples\n",
    "\n",
    "Bootstrap Resampling\n",
    "\n",
    "Creates B bootstrap samples of size n = n from the original dataset\n",
    "For any specific bootstrap (b)\n",
    "Model(s) are fit to the bootstrap sample\n",
    "Model performance is evaluated in the associated out of bag (held-out) samples\n",
    "This is repeated B times such that you have B assessments of model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap aggregating, also called Bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach. Bagging leads to \"improvements for unstable procedures\", which include, for example, artificial neural networks, classification and regression trees, and subset selection in linear regression. On the other hand, it can mildly degrade the performance of stable methods such as K-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets configure Bootstrap\n",
    "\n",
    "n_iterations = 10  #No. of bootstrap samples to be repeated (created)\n",
    "n_size = int(len(df) * 0.50) #Size of sample, picking only 50% of the given data in every bootstrap sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8514285714285714\n",
      "0.8192090395480226\n",
      "0.8171428571428572\n",
      "0.8186813186813187\n",
      "0.8076923076923077\n",
      "0.8547486033519553\n",
      "0.8095238095238095\n",
      "0.8295454545454546\n",
      "0.7988826815642458\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "#Lets run Bootstrap\n",
    "stats = list()\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    #prepare train & test sets\n",
    "    train = resample(values, n_samples = n_size) #Sampling with replacement..whichever is not used in training data will be used in test data\n",
    "    test = np.array([x for x in values if x.tolist() not in train.tolist()]) #picking rest of the data not considered in training sample\n",
    "    \n",
    "    #fit model\n",
    "    model.fit(train[:,:-1], train[:,-1]) #model.fit(X_train,y_train) i.e model.fit(train set, train label as it is a classifier)\n",
    "    \n",
    "    #evaluate model\n",
    "    predictions = model.predict(test[:,:-1]) #model.predict(X_test)\n",
    "    score = accuracy_score(test[:,-1], predictions) #accuracy_score(y_test, y_pred)\n",
    "    #caution, overall accuracy score can mislead when classes are imbalanced\n",
    "    \n",
    "    print(score)\n",
    "    stats.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stats)\n",
    "plt.figure(figsize = (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0 confidence interval 79.9% and 85.4%\n"
     ]
    }
   ],
   "source": [
    "#Lets find Confidence intervals\n",
    "\n",
    "a = 0.95 # for 95% confidence\n",
    "p = ((1.0 - a)/2.0) * 100 #tail regions on right and left .25 on each side indicated by P value (border)\n",
    "                          # 1.0 is total area of this curve, 2.0 is actually .025 thats the space we would want to be \n",
    "                            #left on either side\n",
    "lower = max(0.0, np.percentile(stats,p))\n",
    "\n",
    "p = (a + ((1.0 - a)/ 2.0)) * 100 #p is limits\n",
    "upper = min(1.0, np.percentile(stats,p))\n",
    "print('%.1f confidence interval %.1f%% and %.1f%%' %(a*100, lower*100, upper*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model is likely to give an accuracy score of 86.0% +- 10.621(std dev). Putting this in normal distribution, you will get the score as per Central Limit theorem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Relevant comparisons, strengths/weaknesses for bootstrap for resampling\n",
    "\n",
    "Our performance estimate will have higher bias than K-fold using typical K values (bias equivalent to about K = 2)\n",
    "\n",
    "Although training sets have full n, they only include about 63% unique observations. These models under perform training sets with 80 - 90% unique observations\n",
    "With smaller training set sizes, this bias is considered too high by some (Kuhn)\n",
    "Our performance estimate will have less variance than K-fold\n",
    "\n",
    "Compare SE of accuracy for 100 resamples using k-fold with repeats: 0.0063189 vs. bootstrap: 0.0034271\n",
    "With 1000 bootstraps (and test sets with ~ 37% of n) can get a very precise estimate of test error\n",
    "Can also represent the variance of our test error (like repeated K-fold)\n",
    "\n",
    "Used primarily for selecting among model configurations when you don’t care about bias and just want a precise selection metric\n",
    "\n",
    "Useful in explanation scenarios where you just need the “best” model\n",
    "“Inner loop” of nested cross validation (more on this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Resampling to Select Best Model Configurations\n",
    "Resampling is also used to select best models. Best means the model configuration that performs the best in new data and therefore is closest to the true DGP for the data\n",
    "\n",
    "For example, we might want to select among model configurations in an explanatory scenario to have a principled approach to determine the model configuration that best matches the true DGP (and would be best to test your hypotheses). e.g.,\n",
    "Selecting covariates to include\n",
    "Deciding on X transformations\n",
    "outlier identification approach\n",
    "statistical algorithm\n",
    "We can simply evaluate each configuration using one of the previously described resampling methods\n",
    "We would call the held-out data (the single set, the folds, the OOB samples) a validation set\n",
    "We select the model configuration with the best mean across our resampled validation sets on the relevant performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling methods can be used to select the best model configuration and/or evaluate model performance\n",
    "\n",
    "So far we have done EITHER selection OR evaluation but not both together\n",
    "\n",
    "The concepts to both select the best configuration and evaluation it are similar but it requires different (slightly more complicated) resampling than what we have done so far\n",
    "\n",
    "If you use your held-out resamples to select the best model among a number of model configurations then the same held out resamples cannot also be used to evaluate the performance of that same best model\n",
    "\n",
    "If it is, the performance metric will have ‘optimization bias.’ To the degree that there is any noise (i.e., variance) in the measurement of performance, selecting the best model configuration will capitalize on this noise.\n",
    "\n",
    "You need to use one set of held out resamples (validation sets) to select the best model. Then you need a DIFFERENT set of held out resamples (test sets) to evaluate that best model.\n",
    "\n",
    "There are two strategies for this:\n",
    "\n",
    "Strategy 1: First, hold out a test set for final/best model evaluation. Then use one of the above resampling methods (single validation set approach, k-fold or bootstrap) to select the best model configuration. Bootstrap is likely best option b/c it is typically more precise (though biased)\n",
    "\n",
    "Strategy 2: Nested resampling. More on this in a moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article compared Leave One out CV, K-fold, repeated K fold and Bootstrap resampling on a Logistic Regression configuration model and compared the accuracy of the model after each type of CV was applied while also comparing the tradeoffs of each method with the other in a given condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. Unit 5 Resampling Methods for Model Selection and Evaluation (https://dionysus.psych.wisc.edu/iaml/unit-05.html)\n",
    "2. 3.1. Cross-validation: evaluating estimator performance (https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "3. Linear Regression With Bootstrapping (https://towardsdatascience.com/linear-regression-with-bootstrapping-4924c05d2a9)\n",
    "4. How to Use Approximate Leave-one-out Cross-validation to Build Better Models (https://hackernoon.com/how-to-use-approximate-leave-one-out-cross-validation-to-build-better-models-vg1u35g2)\n",
    "5. RepeatedKFold (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licences:\n",
    "1. Pandas 1.4 https://pandas.pydata.org/docs/getting_started/overview.html\n",
    "2. Logistic Regression sklearn -- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIT License\n",
    "Copyright (c) 2022 Midhun Mohan Kudayattutharayil\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
